

## ü§ñ Planning with Code Execution: The Core Idea

The lecture argues that for complex tasks, it's generally **better** to let the LLM **write and execute code** (like Python or SQL) than to provide it with a small set of **custom tools**.

---

### Key Contrast

| Method | What the LLM Uses | Why It's Better |
| :--- | :--- | :--- |
| **Custom Tools** (Less Effective) | A few **fixed tools** written by a developer. | Toolset is **too limited** and requires constant maintenance for new queries. |
| **Code as Action** (More Effective) | **Full programming language** (e.g., Python/Pandas) and its vast libraries. | Provides a **massive, flexible toolset** that the LLM is already highly proficient in, enabling it to write rich, dynamic plans. |

**In short: Stop writing custom tools; start letting the LLM write the code.** 

## üìù Multi-Agent Systems

This lecture introduced the concept of **Multi-Agent Systems** as a powerful way to handle **complex tasks** by having multiple specialized agents (each powered by an LLM) collaborate.

---

### 1. üí° Why Use Multiple Agents? (The Analogy)

* **Problem:** For a complex task, building one single LLM agent to do everything can be difficult to manage and prone to errors.
* **Analogy:** We break down complex work into:
    * Multiple **processes/threads** on a single computer.
    * A **team of people** with different roles (e.g., a researcher, designer, writer) instead of just one generalist.
* **Benefit:** This approach makes it easier for developers to **decompose a complex task** into smaller, manageable sub-tasks that can be addressed by specialized agents. 

---

### 2. ü§π Creating Specialized Agents (Roles and Tools)

An agent is created by **prompting an LLM** to play a specific role. Each agent is then given the **tools** it needs for its job.

| Agent Role | Example Task | Key Tool(s) Needed |
| :--- | :--- | :--- |
| **Researcher** | Analyze market trends and competitor offerings. | **Web Search** |
| **Graphic Designer** | Create visualizations, charts, and artwork. | **Image Generation/Manipulation APIs**, **Code Execution** (for charts) |
| **Writer** | Transform research into report text/marketing copy. | **No specific tools** (uses LLM's core text generation ability) |
| **Marketing Manager** | Coordinate and review the work of the team. | **(Acts as an Orchestrator)** |

---

### 3. üó∫Ô∏è Communication Patterns (Workflows)

The lecture showed two ways agents can work together, which defines the **communication pattern** or workflow:

* **1. Linear Workflow (Pipeline):**
    * The simplest pattern where one agent's output immediately becomes the next agent's input.
    * **Example:** Research Agent $\rightarrow$ Graphic Designer Agent $\rightarrow$ Writer Agent $\rightarrow$ Final Report.
    * **Advantage:** Simple to design and debug.
* **2. Manager/Coordinator Workflow (Delegation):**
    * A **manager agent** (the LLM) is at the top. It receives the complex request, determines a plan, and delegates specific tasks to the worker agents.
    * The workers report back to the manager.
    * **Example:** Marketing Manager Agent plans: 1. Ask researcher. 2. Ask designer. 3. Ask writer. 4. **Review/Improve final report.** (The manager acts as a fourth agent).
    * **Advantage:** Allows for dynamic planning, reflection, and final quality control by the managing agent.

---

### ‚úÖ Conclusion

Building a multi-agent system allows you to build **reusable** and **highly specialized** agents that collectively solve complex problems more effectively than a single, generalized agent. Designing the right **communication pattern** is key to success.

That's the key question in multi-agent systems! While they may share the **same core LLM model**, they are fundamentally different because of three strategic factors: **Role Prompting, Specialized Toolsets, and Memory/Context.**

May using the same LLM, then what makes the difference:

---

## üé≠ 1. Role Prompting (The Persona)

The primary differentiator is the **System Prompt** (or instruction) given to the LLM instance. This prompt defines the agent's entire persona and purpose.

* **Instruction:** It explicitly tells the LLM what it is, its expertise, and how it should behave.
* **Focus:** This forces the massive, general-purpose LLM to narrow its focus and adopt a specific mindset, drawing only on the knowledge and logic relevant to that role.
    * Example: A prompt for a **"Researcher Agent"** instructs the LLM to be *objective, factual, and thorough*, prioritizing information retrieval.
    * Example: A prompt for a **"Writer Agent"** instructs the LLM to be *creative, concise, and focused on marketing copy*, prioritizing language generation.

This is why, even though both agents use the same underlying "brain," the Researcher will naturally spend tokens thinking about web search queries, while the Writer will spend tokens thinking about tone and formatting.

---

## üõ†Ô∏è 2. Specialized Toolsets (The Capabilities)

Each agent is only given access to the **external tools** (APIs or functions) it needs to perform its job.

* **Enforcement:** This physically limits what the agent can *do* and guides its planning. The LLM is forced to consider a plan that only involves its available tools.
* **Examples:**
    * The **Researcher Agent** is given the `web_search()` tool.
    * The **Graphic Designer Agent** is given the `generate_image()` and `execute_code()` (for charts) tools.
    * The **Writer Agent** may be given no tools at all, as its task is pure text generation.

By limiting the available functions, the planning and reasoning of the underlying LLM are fundamentally altered for that specific role. 

---

## üß† 3. Context and State (The Memory)

In a multi-agent workflow, the agents often have different **memory or context**.

* **Input Context:** An agent only receives the specific, relevant input from the previous agent or the supervisor. It doesn't have the full conversation history or the previous agent's internal thought process. This limits the context the LLM has to reason over.
* **State:** The state, or current task progress, is unique to that agent's current step. This further reinforces the distinction by making each agent focus only on its assigned sub-goal.

In essence, you are not just using the same LLM multiple times; you are creating **multiple instances of a specialized thinking machine** by wrapping the LLM in a unique set of **instructions, permissions (tools), and data inputs.**
